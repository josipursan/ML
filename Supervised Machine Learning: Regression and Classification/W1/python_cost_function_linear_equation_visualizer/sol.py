"""
This file contains the solution for my first TO DO outlined here : https://github.com/josipursan/ML/blob/main/Supervised%20Machine%20Learning%3A%20Regression%20and%20Classification/Notes.md#cost-function-intuition
"""

import random
import time

import numpy as np
import matplotlib.pyplot as plt

random.seed(time.time())

def f(x):
    return x**3 / (x**0.5 * x*1.2)**0.5    #random function generating a nice, non-linaer, convex-ish parabola

def main():
    x_vals = np.arange(1.0, 20.0, 1.4)
    y_vals = f(x_vals)
    plt.plot(x_vals, y_vals, 'r')   # line of original, real function is drawn as a red, solid line
    #plt.show()

    # We assume we are searching for a model of linear eq format : y = f(x) = wx + b
    # We will randomly generate a random number of w,b pairs, and then compute cost function for each such function, as well a plot these linear equations to plot
    number_of_lines_to_generate = random.randrange(20) #this means we will generate max of 20 random linear lines
    w_b_pairs = []  # array of arrays; each subarray represents [w,b] values in that order
    for i in range(0, number_of_lines_to_generate):
        temp = []
        temp.append(random.uniform(-50.0, 100.0))
        temp.append(random.uniform(-50.0, 100.0))
        w_b_pairs.append(temp)
    
    # Now we have our "models" - that's just the w,b pairs representing various predictions our "learning" process made (the learning process being this for loop above xD)
    # We will run x_vals through our "models" now

    all_y_hat_vals = []
    for i in range(0, number_of_lines_to_generate):
        temp = w_b_pairs[i][0] * x_vals + w_b_pairs[i][1]
        all_y_hat_vals.append(temp)
    
    # Now we will compute all costs - we will compare y_predicted to the respective pair belonging from y_vals, and store this compute value to all_costs
    all_costs = []
    for current_model in range(0, number_of_lines_to_generate):
        temp_cost = -1
        for i in range(0, len(y_vals)):
            temp_cost += (all_y_hat_vals[current_model][i] - y_vals[i])**2
        temp_cost = (1/2*len(y_vals)) * temp_cost
        all_costs.append(temp_cost)

    print("All costs : {}\n".format(all_costs))
    print("Smallest cost in list is : {}\n".format(min(all_costs)))
    index_model_smallest_cost = all_costs.index(min(all_costs))
    print("Index of smallest cost in list is : {}\n".format(index_model_smallest_cost))
    plt.plot(x_vals, all_y_hat_vals[index_model_smallest_cost], linestyle='dashed', color='teal', linewidth=2, label="BEST FIT")

    for i in range(0, number_of_lines_to_generate):
        if i == index_model_smallest_cost:
            continue
        plt.plot(x_vals, all_y_hat_vals[i], linestyle='dotted', label=i, alpha=0.3)     # lines generated by our "models" are drawn as dotted lines, with different line color for each line

    plt.legend(loc="upper left")
    plt.show()

    # Cost eq : J = (1/2m)*(y_model_output - y_real_val)**2 for each available element from x_vals
main()